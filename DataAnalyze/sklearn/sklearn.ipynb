{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom subprocess import check_output\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train = pd.read_csv(\"../input/train.csv\", header=None)\n# header: 指定行来作为列的名字。默认为0，即默认第一行为列名。\n# None说明数据本身有列名。\ntrainLabel = pd.read_csv('../input/trainLabels.csv', header=None)\ntest = pd.read_csv('../input/test.csv', header=None)\nprint(plt.style.available) # 查看可用的绘图样式\nplt.style.use('ggplot')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1840c0a625cdab2f839572b47ff9cd2474b3b215"
      },
      "cell_type": "code",
      "source": "print('train shape:', train.shape)\nprint('test shape:', test.shape)\nprint('trainLabel shape:', trainLabel.shape)\ntrain.head()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "41cca8fafdf625e76a0a9600d6e763b40757e285"
      },
      "cell_type": "code",
      "source": "train.info()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "650c10d907b08810adf6bf8b9805c9bcf6ba9aad"
      },
      "cell_type": "code",
      "source": "train.describe()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1d7c55b5bbe3e219484612d7a049bfc10eae9a9c"
      },
      "cell_type": "markdown",
      "source": "### 使用kNN进行分类"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f12edc08aa3368925006ceaa3006f3464b8b4524"
      },
      "cell_type": "code",
      "source": "# kNN with cross-validation\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score, train_test_split\n\nX,y = train, np.ravel(trainLabel) \n# np.ravel: 将多维数据降为一维，返回的是视图。\n# 即若对y进行修改，则trainLabel同时被修改。同时还有np.flatten()，拷贝非视图。\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9348f1c54e98dc467a8fe9dc67802d73911cf4ad"
      },
      "cell_type": "code",
      "source": "neig = np.arange(1,25)\nkfold = 10\ntrain_accuracy = []\nval_accuracy = []\nbestKnn = None\nbestAcc = 0.0\n# Loo over different values of k\nfor i,k in enumerate(neig): # enumerate(): 同时列出数据和数据下标\n    # k from 1 to 25\n    knn = KNeighborsClassifier(n_neighbors=k)\n    knn.fit(X_train, y_train)\n    # train accuracy\n    train_accuracy.append(knn.score(X_train, y_train))\n    # test accuracy\n    val_accuracy.append(np.mean(cross_val_score(knn, X, y, cv=kfold)))\n    if np.mean(cross_val_score(knn, X, y, cv=kfold)) > bestAcc:\n        bestAcc = np.mean(cross_val_score(knn, X, y, cv=10))\n        bestKnn = knn\n\n# Plot\nplt.figure(figsize=[13,8])\nplt.plot(neig, val_accuracy, label='Validation Accuracy')\nplt.plot(neig, train_accuracy, label='Training Accuracy')\nplt.legend() # set the position of figure\nplt.title('k value VS Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.xticks(neig) \nplt.show()\n\nprint('Best Accuracy without feature scaling:', bestAcc)\nprint(bestKnn)\n    ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4790467eb5d8159a17621581aed73bafcd9b43cc"
      },
      "cell_type": "code",
      "source": "# predict test\ntest_fill = np.nan_to_num(test)\n# replace nan with 0 and replace infinite with finite numbers\nsubmission = pd.DataFrame(bestKnn.predict(test_fill))\nprint(submission.shape)\nsubmission.columns = ['Solution']\nsubmission['Id'] = np.arange(1, submission.shape[0]+1)\nsubmission = submission[['Id', 'Solution']]\nsubmission",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "962c07ef5916e79e4eb3d3f1caa83cff13fb6d2e"
      },
      "cell_type": "code",
      "source": "submission.to_csv('submission_no_normalization.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "535876c01637c11d951673e4c3bdfc65df5a0ebc"
      },
      "cell_type": "code",
      "source": "print(check_output([\"ls\", \"../working\"]).decode(\"utf8\"))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "2e294b51c8e8cb686b5962b6d72a8cbf4414158f"
      },
      "cell_type": "markdown",
      "source": "### Add Feature Scaling"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f25e5536aabd8e45ed9fbfc156ade0663ef9d3f7"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n\nstd = StandardScaler() \n# 通过删除均值和缩放到单位方差来标准化特征\nX_std = std.fit_transform(X)\nmms = MinMaxScaler()\n# 将属性缩放到一个指定的最大和最小值（通常为1-0）之间\nX_mms = mms.fit_transform(X) \nnorm = Normalizer()\n# 标准化，将数据按比例缩放，使之落入一个小的特定区间\nX_norm = norm.fit_transform(X) ",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e765c629c67945105f040e760d3e6abd87fc0469"
      },
      "cell_type": "code",
      "source": "neig = np.arange(1,30)\nkfold = 10\nval_accuracy = {'std':[], 'mms':[], 'norm':[]}\nbestKnn = None\nbestAcc = 0.0\nbestScaling = None\n# Loop over different values of k\nfor i,k in enumerate(neig):\n    knn = KNeighborsClassifier(n_neighbors=k)\n    s1 = np.mean(cross_val_score(knn, X_std, y, cv=kfold))\n    val_accuracy['std'].append(s1)\n    s2 = np.mean(cross_val_score(knn, X_mms, y, cv=kfold))\n    val_accuracy['mms'].append(s2)\n    s3 = np.mean(cross_val_score(knn, X_norm, y, cv=kfold))\n    val_accuracy['norm'].append(s3)\n    if s1 > bestAcc:\n        bestAcc = s1\n        bestKnn = knn\n        bestScaling = 'std'\n    if s2 > bestAcc:\n        bestAcc = s2\n        bestKnn = knn\n        bestScaling = 'mms'\n    if s3 > bestAcc:\n        bestAcc = s3\n        bestKnn = knn\n        bestScaling = 'norm'\n# Plot\nplt.figure(figsize=[13,8])\nplt.plot(neig, val_accuracy['std'], label='CV Accuracy with std')\nplt.plot(neig, val_accuracy['mms'], label='CV Accuracy with mms')\nplt.plot(neig, val_accuracy['norm'], label='CV Accuracy with norm')\nplt.legend()\nplt.title('k values VS Accuracy')\nplt.xlabel('Number of Neighbors')\nplt.ylabel('Accuracy')\nplt.xticks(neig)\nplt.show()\n\nprint('Best Accuracy with feature scaling:', bestAcc)\nprint('Best kNN classifier:', bestKnn)\nprint('Best Scaling:', bestScaling)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ae4890536629d1ca2ccfc19ac566418d9073f56"
      },
      "cell_type": "code",
      "source": "# predict on test\nbestKnn.fit(X_norm, y)\nsubmission = pd.DataFrame(bestKnn.predict(norm.transform(test_fill)))\nprint(submission.shape)\nsubmission.columns = ['Solution']\nsubmission['Id'] = np.arange(1, submission.shape[0]+1)\nsubmission = submission[['Id','Solution']]\nsubmission",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7a75688adbd8570d9880d52a5ddd6b7d0fa95a53"
      },
      "cell_type": "code",
      "source": "submission.to_csv('submission_with_scaling.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "265ddfc37d0ffcc62c097fc508d2f9beeb95fd53"
      },
      "cell_type": "code",
      "source": "print(check_output(['ls','../working']).decode('utf8'))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ae12169112bd0dceea9603b6420c1eb0074bf4d6"
      },
      "cell_type": "markdown",
      "source": "### Feature Selection"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a62db60eeabd58ba4c6a74a4cfda1a075d6f510b"
      },
      "cell_type": "code",
      "source": "f,ax = plt.subplots(figsize=(18,18))\nsns.heatmap(pd.DataFrame(X_std).corr(), annot=True, linewidths=.5, fmt='.1f',ax=ax)\n# annot: annotate为True时，在heatmap中每个方格写入数据。\n# linewidths: 热力图矩阵之间的间隔大小\n# fmt: 格式设置",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "079be06d11b6a82ba4918bdef07903d02852b2ad"
      },
      "cell_type": "code",
      "source": "from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score, confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n# split data 70% train and 30% val\nX_train ,X_val, y_train, y_val = train_test_split(X_std, y, test_size=0.3, random_state=42)\n# random_state: 设置相同的random_state值，则多次执行结果相同，可以完全复现结果。\n# 若设置为None，则会随机选择一个种子。\n\n# random forest classifier with n_estimators=10(default)\nclf_rf = RandomForestClassifier(random_state=43)\nclr_rf = clf_rf.fit(X_train, y_train)\n\nac = accuracy_score(y_val, clr_rf.predict(X_val))\n# 计算模型预测准确率\nprint('Accuracy is:', ac)\ncm = confusion_matrix(y_val, clf_rf.predict(X_val))\n# confusion_matrix: 混淆矩阵，列为真实值，行为预测值。\n# 通过矩阵的形式表现预测结果如何。\nsns.heatmap(cm, annot=True, fmt=\"d\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "544a8daf84c0797a8d47519209945bbd2fdfb7d2"
      },
      "cell_type": "code",
      "source": "from sklearn.svm import SVC\nfrom sklearn.feature_selection import RFECV\n# 递归特征消除（Recursive feature elimination)\n# 递归特征消除通过反复构建模型来选出最好的（或最差的）特征（根据系数来选）。\n# 把选出来的特征放置一边，然后在剩余的特征上重复上述过程，直到遍历所有特征。\n\nkfold = 10\nbestSVC = None\nbestAcc = 0.0\nval_accuracy = []\ncv_range = np.arange(5,11)\nn_feature = []\nfor cv in cv_range:\n    # Create the RFE object and compute a cross-validated score.\n    svc = SVC(kernel='linear')\n    # classifications\n    rfecv = RFECV(estimator=svc, step=1, cv=cv, scoring='accuracy')\n    rfecv.fit(X_std, y)\n    # estimator: 估计函数，底层的回归模型。\n    # step: 对应迭代过程中每次移除的属性的数量。\n    # n_features_: 选择特征的数量。\n    # support_: 返回一个长度为[n_features]的向量，为True或False，最佳属性为True。\n    # ranking_: 返回特征的排序\n    # ranking_[i]: 返回第i个特征的排序位置\n    val_accuracy += [np.mean(cross_val_score(svc, X_std[:, rfecv.support_], y, cv=kfold))]\n    # cross_val_score: 通过交叉验证评估模型分数\n    # 将最新计算得出的准确率加入val_accuracy中\n    n_feature.append(rfecv.n_features_)\n    if val_accuracy[-1] > bestAcc:\n        # val_accuracy[-1]返回最新加入的accuracy\n        bestAcc = val_accuracy[-1]\n\n# Plot\nplt.figure(figsize=[13,8])\nplt.plot(cv_range, val_accuracy, label='CV Accuracy')\nfor i in range(len(cv_range)):\n    plt.annotate(str(n_feature[i]), xy=(cv_range[i], val_accuracy[i]))\n    # annotate: 文字标注 str():标注内容，xy:标注位置\nplt.legend()\nplt.title('Cross Validation Accuracy')\nplt.xlabel('k fold')\nplt.ylabel('Accuracy')\nplt.show()\n\nprint('Best Accuracy with feature scaling and RFECV:', bestAcc)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "752eb0588e3e526e8574874924f5538f2d7f3890"
      },
      "cell_type": "code",
      "source": "from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.ensemble import VotingClassifier\n\nx_train = train\ny_train = trainLabel\nx_test = test\nx_train = np.asarray(x_train)\ny_train = np.asarray(y_train)\nx_test = np.asarray(x_test)\ny_train = y_train.ravel()\n# ravel(): 将数据转换为1维\nprint('training_x shape:', x_train.shape, ',training_y shape:', y_train.shape, ',testing_x shape:', x_test.shape)\n\n# checking the models\nx_all = np.r_[x_train, x_test]\n# np.r_: 按row来组合array\nprint('x_all shape:', x_all.shape)\n\n# using the gaussian mixture model\nfrom sklearn.mixture import GaussianMixture\nlowest_bic = np.infty\nbic = []\nn_components_range = range(1,7)\ncv_types = ['spherical', 'tied', 'diag', 'full']\nfor cv_type in cv_types:\n    for n_components in n_components_range:\n        # Fit a mixture of Gaussians with EM\n        gmm = GaussianMixture(n_components=n_components, covariance_type=cv_type)\n        gmm.fit(x_all)\n        bic.append(gmm.aic(x_all))\n        if bic[-1] < lowest_bic:\n            lowest_bic = bic[-1]\n            best_gmm = gmm\n        \nbest_gmm.fit(x_all)\nx_train = best_gmm.predict_proba(x_train)\nx_test = best_gmm.predict_proba(x_test)\n\n# Taking only two models for keeping it simple\nknn = KNeighborsClassifier()\nrf = RandomForestClassifier()\n\nparam_grid = dict()\n# Grid search for best tuning parameters for KNN\ngrid_search_knn = GridSearchCV(knn, param_grid=param_grid, cv=10, scoring='accuracy').fit(x_train, y_train)\nprint('best estimator KNN:', grid_search_knn.best_estimator_, 'Best Score', grid_search_knn.best_estimator_.score(x_train, y_train))\nknn_best = grid_search_knn.best_estimator_\n\n# Grid search for best tuning parameters for RandomForest\ngrid_search_rf = GridSearchCV(rf, param_grid=dict(), verbose=3, scoring='accuracy', cv=10).fit(x_train, y_train)\nprint('best estimator RandomForest:', grid_search_rf.best_estimator_, 'Best Score:', grid_search_knn.best_estimator_.score(x_train, y_train))\nrf_best = grid_search_rf.best_estimator_\n\nknn_best.fit(x_train, y_train)\nprint(knn_best.predict(x_test)[0:10])\nrf_best.fit(x_train, y_train)\nprint(rf_best.predict(x_test)[0:10])\n\n# scoring the models\nprint('Score for KNN:', cross_val_score(knn_best,x_train,y_train,cv=10,scoring='accuracy').mean())\nprint('Score for Random Forest:', cross_val_score(rf_best, x_train, y_train, cv=10, scoring='accuracy').max())\n\n# framing our solution\nknn_best_pred = pd.DataFrame(knn_best.predict(x_test))\nrf_best_pred = pd.DataFrame(rf_best.predict(x_test))\n\nknn_best_pred.index += 1\nrf_best_pred.index += 1\n\nrf_best_pred.columns = ['Solution']\nrf_best_pred['Id'] = np.arange(1, rf_best_pred.shape[0]+1)\nrf_best_pred = rf_best_pred[['Id','Solution']]\nprint(rf_best_pred)\n\nrf_best_pred.to_csv('Submission_rf.csv', index=False)\n# index: 若为True，则写入行名称",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}